<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Self-Transcendence">
  <meta name="keywords" content="REPA, Beyond External Guidance">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Beyond External Guidance: Unleashing the Semantic Richness
Inside Diffusion Transformers for Improved Training
</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <!-- <link rel="icon" href="./static/images/favicon.svg"> -->

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

  
  
<!-- <nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://keunhong.com">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://hypernerf.github.io">
            HyperNeRF
          </a>
          <a class="navbar-item" href="https://nerfies.github.io">
            Nerfies
          </a>
          <a class="navbar-item" href="https://latentfusion.github.io">
            LatentFusion
          </a>
          <a class="navbar-item" href="https://photoshape.github.io">
            PhotoShape
          </a>
        </div>
      </div>
    </div>

  </div>
</nav> -->

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Beyond External Guidance: Unleashing the Semantic Richness
Inside Diffusion Transformers for Improved Training
</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=ZCDjTn8AAAAJ&hl">Lingchen Sun</a><sup>1,2</sup>,</span>
            <span class="author-block">
              <a href="https://cswry.github.io/">Rongyuan Wu</a><sup>1.2</sup>,</span>
            <span class="author-block">
              <a href="https://xtudbxk.github.io/">Zhengqiang Zhang</a><sup>1.2</sup>,
            </span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=FMNs2K0AAAAJ&hl=en">Ruibin Li</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://yjsunnn.github.io/">Yujing Sun</a><sup>1,2</sup>,
            </span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=wzdCc-QAAAAJ&hl">Shuaizheng Liu</a><sup>1,2</sup>,
            </span>
            <span class="author-block">
              <a href="https://www4.comp.polyu.edu.hk/~cslzhang/">Lei Zhang</a><sup>1,2</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>The Hong Kong Polytechnic University ,</span>
            <span class="author-block"><sup>2</sup>OPPO Research Institute</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2011.12948"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Arxiv(TBD)</span>
                </a>
              </span>
              <!-- <span class="link-block">
                <a href="https://arxiv.org/abs/2011.12948"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span> -->
              <!-- Video Link. -->
              <!-- <span class="link-block">
                <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> -->
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/csslc/Self-Transcendence"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <!-- <span class="link-block">
                <a href="https://github.com/google/nerfies/releases/tag/0.1"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a> -->
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- <section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video id="teaser" autoplay muted loop playsinline height="100%">
        <source src="./static/videos/teaser.mp4"
                type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        <span class="dnerf">Nerfies</span> turns selfie videos from your phone into
        free-viewpoint
        portraits.
      </h2>
    </div>
  </div>
</section> -->

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img id="teaser" src="./static/images/vis_com_256.png" alt="Teaser Image" style="width: 100%; height: auto;">
      <!-- <h2 class="subtitle has-text-centered">
        <span class="dnerf">你的项目名</span> 你的项目描述文字
      </h2> -->
    </div>
  </div>
</section>

  

<!-- <section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-steve">
          <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/steve.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-chair-tp">
          <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/chair-tp.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-shiba">
          <video poster="" id="shiba" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/shiba.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-fullbody">
          <video poster="" id="fullbody" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/fullbody.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-blueshirt">
          <video poster="" id="blueshirt" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/blueshirt.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-mask">
          <video poster="" id="mask" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/mask.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-coffee">
          <video poster="" id="coffee" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/coffee.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-toby">
          <video poster="" id="toby" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/toby2.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section> -->



<!-- Overview section -->
<section class="section" style="padding-top: 2rem; padding-bottom: 2rem;">
  <div class="container is-max-desktop">
    <h2 class="title is-3">Overview</h2>
    <div class="content has-text-justified">  
      <!-- 浅蓝色高亮框 -->
      <div style="background-color: #e8f4f8; padding: 1.5rem; border-radius: 8px; margin: 1.5rem 0; border-left: 4px solid #209cee;">
        <p style="margin-bottom: 0;">
          <strong>[Question]</strong>: Can <strong>internal</strong> features be used as effective semantic guidance signals to improve the training of DiT models? 
        </p>
      </div>
      <div style="background-color: #edfbf0; padding: 1.5rem; border-radius: 8px; margin: 1.5rem 0; border-left: 4px solid #48c774;">
        <p style="margin-bottom: 0;">
          <strong>[Answer]</strong>: Yes! It can even provide <strong>better</strong> feature guidance than external pretrained DINO features used in REPA.
        </p>
      </div>

      <div style="background-color: #e8f4f8; padding: 1.5rem; border-radius: 8px; margin: 1.5rem 0; border-left: 4px solid #209cee;">
        <p style="margin-bottom: 0;">
          <strong>[Question]</strong>: Could <strong>any</strong> feature be effective guidance? 
        </p>
      </div>
      <div style="background-color: #edfbf0; padding: 1.5rem; border-radius: 8px; margin: 1.5rem 0; border-left: 4px solid #48c774;">
        <p style="margin-bottom: 1rem;">
          <strong>[Answer]</strong>: No. We find that the most effective guiding features should meet <strong>two criteria</strong>:
          </p>
          <p style="margin-bottom: 0.5rem;">
            <strong>(1)</strong> They should have a <strong>clean structure</strong>, in the sense that they can effectively help shallow blocks distinguish noise from signal.
          </p>
          <p style="margin-bottom: 0;">
            <strong>(2)</strong> They should be <strong>semantically discriminative</strong>, making it easier for shallow layers to learn effective representations.
          </p>
        </p>
      </div>
      
      <!-- 方法图片 -->
      <div style="text-align: center; margin: 2rem 0;">
        <img src="./static/images/page1.png" alt="Overview Figure" 
             style="max-width: 100%; height: auto; border-radius: 8px;">
        <p style="margin-top: 0.5rem; font-size: 0.9rem; color: #666;">
          REPA leverages pre-trained DINO model features to effectively highlight semantically meaningful regions. 
          In comparison, SRA and LayerSync rely on internal features from the in-training model, whose weak semantic representation limits their guidance for shallow layers. 
          Instead, our approach generates features with <strong>clearer structural organization and richer semantics</strong>.
        </p>
      </div>
    </div>
  </div>
</section>


<!-- Framework section -->
<section class="section" style="padding-top: 2rem; padding-bottom: 2rem;">
  <div class="container is-max-desktop">
    <h2 class="title is-3">Method</h2>
    <div class="content has-text-justified">

      <p>
        We propose a two-stage training framework, namely <strong>Self-Transcendence</strong>. 
      </p>
      <p>
        Firstly, we use clean VAE features as guidance to help the model distinguish useful information from noise in shallow layers.
        After a certain number of iterations, the model has learned more meaningful representations. 
      </p>
      
      <p>  
        We then freeze this model
        and use its representation as a fixed teacher. To enhance the semantic expression in the features, we build a self-guided representation that better aligns with the target conditions.
      </p>
      
      
      <!-- 方法图片 -->
      <div style="text-align: center; margin: 2rem 0;">
        <img src="./static/images/framework.png" alt="Framework Figure" 
             style="max-width: 40%; height: auto; border-radius: 8px;">
        <p style="margin-top: 0.5rem; font-size: 0.9rem; color: #666;">
          The <strong>framework</strong> of our proposed Self-Transcendence.
          The spark icon indicates that the parameters of this layer are trainable, while the snowflake icon indicates that they are frozen.
        </p>
      </div>
    </div>
  </div>
</section>


  
<!-- Result section -->
<section class="section" style="padding-top: 2rem; padding-bottom: 2rem;">
  <div class="container is-max-desktop">
    <h2 class="title is-3">Result</h2>
    <div class="content has-text-justified">
      
      <!-- 第三个子部分 -->
      <h3 style="font-size: 1.4rem; font-weight: bold; color: #2c3e50; margin: 2rem 0 1rem 0;">
        Self-Transcendence demonstrates superior class separability.
      </h3>
      <p>
        Despite the powerful semantic separability obtained by REPA, it heavily relies on extensive and time-consuming pre-training
        with external data, which may not always be feasible and desirable. Though some recent methods such as LayerSync and SRA achieve
        self-acceleration, their features lack stable structural guidance and semantic separability for training. Instead, our
        Self-Transcendence not only achieves self-acceleration, but also demonstrates comparable semantic separability with REPA.
  
      </p>
      
      <!-- 图片3 -->
      <div style="text-align: center; margin: 2rem 0;">
        <img src="./static/images/motivation.png" alt="Motivation Study" 
             style="max-width: 50%; height: auto; border-radius: 8px;">
        <p style="margin-top: 0.5rem; font-size: 0.9rem; color: #666;">
          <strong>t-SNE visualizations</strong> of the guiding features extracted from (a) REPA, (b) LayerSync, (c) VAE features, and (d)
          our Self-Transcendence with t = 0.4 in the 200K iteration of SiTXL/2. Different colors represent different classes. As REPA, our
          internal guiding features demonstrate superior class separability.
      </div>

      <!-- 第1个子部分 -->
      <h3 style="font-size: 1.4rem; font-weight: bold; color: #2c3e50; margin: 2rem 0 1rem 0;">
         Self-Transcendence is easier, more efficient and more effective.
      </h3>
      <p>
        Compared to methods using external features like REPA, our Self-Transcendence is easier and more efficient without using external data. 
        And still, it outperforms all other self-contained techniques,
        achieving results comparable to or even better than REPA.
      </p>
      
      <!-- 图片1 -->
      <div style="text-align: center; margin: 2rem 0;">
        <img src="./static/images/result.png" alt="Quantitative Results" 
             style="max-width: 80%; height: auto; border-radius: 8px;">
        <p style="margin-top: 0.5rem; font-size: 0.9rem; color: #666;">
          Comparisons with acceleration methods across different backbones on ImageNet. ↓ and ↑ indicate
          whether lower or higher values are better, respectively
        </p>
      </div>
      
      <!-- 第2个子部分 -->
      <h3 style="font-size: 1.4rem; font-weight: bold; color: #2c3e50; margin: 2rem 0 1rem 0;">
        Self-Transcendence obtains better structural generation.
      </h3>
      <p>
        We compare the vanilla SiT model, REPA-enhanced model, and our trained model across 100K to 400K iterations on two ImageNet classes, as
        illustrated in Fig.4. Both our model and REPA show faster
        convergence than the vanilla SiT model, and our method
        tends to obtain better structural generation. For example, in
        the shoe class, our method generates more realistic shapes
      </p>
      
      <!-- 图片2 -->
      <div style="text-align: center; margin: 2rem 0;">
        <img src="./static/images/interactivegen.png" alt="interactivegen Figure" 
             style="max-width: 80%; height: auto; border-radius: 8px;">
        <p style="margin-top: 0.5rem; font-size: 0.9rem; color: #666;">
          <strong>Visual comparison</strong> of generated samples from SiT-XL/2 models at different training iterations. For all models, we apply the same seed, noise, and sampling strategy with a CFG scale of 4.0.
        </p>
      </div>
    </div>
  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@inproceedings{sun2026beyond,
  title     = {Beyond External Guidance: Unleashing the Semantic Richness Inside Diffusion Transformers for Improved Training},
  author    = {Lingchen Sun and Rongyuan Wu and Zhengqiang Zhang and Ruibin Li and Yujing Sun and Shuaizheng Liu and Lei Zhang},
  year      = {2026},
}</code></pre>
  </div>
</section>

</body>
</html>
